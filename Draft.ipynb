{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect claims to fact check in political debates\n",
    "\n",
    "In this project you will implement various classifiers using both neural and feature based technqiues to detect which sentences in political debates should be fact checked.\n",
    "Dataset from ClaimBuster: https://zenodo.org/record/3609356 \n",
    "Evaluate your classifiers using the same metrics as http://ranger.uta.edu/~cli/pubs/2017/claimbuster-kdd17-hassan.pdf (Table 2)\n",
    "\n",
    "Classification report from sklearn provides everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Create advanced model(s) (suggestions are given below)\n",
    "#           -- Generate more features that a model can use. For example the context around the sentence, sentiment, named entities etc.\n",
    "#           -- Rule based classifier. For example, if sentence contains certain words, tags, statistics etc.\n",
    "#           -- Deep learning (word embeddings, transformer models etc.)\n",
    "#           -- Sub-sentence classifier. Long sentences may include several claims, so the goal is to mark the span of claim(s) within a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracemalloc import stop\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import string\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import json\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>date</th>\n",
       "      <th>mos_before_election</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8211</td>\n",
       "      <td>Now, this is not standing still.</td>\n",
       "      <td>Richard M. Nixon</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.417840</td>\n",
       "      <td>-1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8515</td>\n",
       "      <td>So these are three programs which are quite mo...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>418</td>\n",
       "      <td>0.249581</td>\n",
       "      <td>-1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8514</td>\n",
       "      <td>The proposal advanced by you and by Mr. Javits...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>42</td>\n",
       "      <td>417</td>\n",
       "      <td>-0.626563</td>\n",
       "      <td>1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8513</td>\n",
       "      <td>It does not put a deficit on the Treasury.</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>416</td>\n",
       "      <td>-0.629486</td>\n",
       "      <td>1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8512</td>\n",
       "      <td>The third is medical care for the aged which i...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>22</td>\n",
       "      <td>415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23528</th>\n",
       "      <td>34028</td>\n",
       "      <td>First of all, the media is so dishonest and so...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>17</td>\n",
       "      <td>907</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23529</th>\n",
       "      <td>34027</td>\n",
       "      <td>What I've seen -- what I've seen is so bad.</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>906</td>\n",
       "      <td>-0.669600</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23530</th>\n",
       "      <td>34026</td>\n",
       "      <td>I'll look at it at the time.</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>34039</td>\n",
       "      <td>So I talk about the corrupt media.</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23532</th>\n",
       "      <td>33341</td>\n",
       "      <td>They work hard, they do everything they can to...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Secretary of State</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>14</td>\n",
       "      <td>220</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23533 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence_id                                               Text  \\\n",
       "index                                                                   \n",
       "0             8211                   Now, this is not standing still.   \n",
       "1             8515  So these are three programs which are quite mo...   \n",
       "2             8514  The proposal advanced by you and by Mr. Javits...   \n",
       "3             8513         It does not put a deficit on the Treasury.   \n",
       "4             8512  The third is medical care for the aged which i...   \n",
       "...            ...                                                ...   \n",
       "23528        34028  First of all, the media is so dishonest and so...   \n",
       "23529        34027        What I've seen -- what I've seen is so bad.   \n",
       "23530        34026                       I'll look at it at the time.   \n",
       "23531        34039                 So I talk about the corrupt media.   \n",
       "23532        33341  They work hard, they do everything they can to...   \n",
       "\n",
       "                Speaker       Speaker_title Speaker_party         File_id  \\\n",
       "index                                                                       \n",
       "0      Richard M. Nixon      Vice President    REPUBLICAN  1960-09-26.txt   \n",
       "1       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "2       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "3       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "4       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "...                 ...                 ...           ...             ...   \n",
       "23528      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23529      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23530      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23531      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23532   Hillary Clinton  Secretary of State      DEMOCRAT  2016-10-19.txt   \n",
       "\n",
       "       Length  Line_number  Sentiment  Verdict       date  mos_before_election  \n",
       "index                                                                           \n",
       "0           6          114  -0.417840       -1 1960-09-26                    2  \n",
       "1           9          418   0.249581       -1 1960-09-26                    2  \n",
       "2          42          417  -0.626563        1 1960-09-26                    2  \n",
       "3           9          416  -0.629486        1 1960-09-26                    2  \n",
       "4          22          415   0.000000       -1 1960-09-26                    2  \n",
       "...       ...          ...        ...      ...        ...                  ...  \n",
       "23528      17          907   0.032300       -1 2016-10-19                    1  \n",
       "23529       9          906  -0.669600       -1 2016-10-19                    1  \n",
       "23530       7          905   0.000000       -1 2016-10-19                    1  \n",
       "23531       7          918   0.000000       -1 2016-10-19                    1  \n",
       "23532      14          220   0.361200       -1 2016-10-19                    1  \n",
       "\n",
       "[23533 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = pd.read_csv(\"data/crowdsourced.csv\", encoding='utf-8')\n",
    "file2 = pd.read_csv(\"data/groundtruth.csv\", encoding='utf-8')\n",
    "df = pd.concat([file1, file2])\n",
    "\n",
    "\n",
    "df[\"date\"] = df[\"File_id\"].str.strip(to_strip=\".txt\")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.sort_values(\"date\", inplace= True)\n",
    "df[\"mos_before_election\"] = 11 - df[\"date\"].dt.month\n",
    "\n",
    "df['index'] = pd.RangeIndex(len(df))\n",
    "df.set_index('index', inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_clean'] = df['Text']\n",
    "#punct = string.punctuation\n",
    "characters = string.punctuation + '–0123456789‘’“”' \n",
    "translator = str.maketrans('', '', characters)\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"i'm\", \"i've\", \"i'll\", \"i'd\", \"  \", 'uh', \"ah\", \"aah\", 'weve', \"we've\", \"we'd\", \"we'll\",  \"we're\",\n",
    "'aah', 'aarp', 'aayuh', 'ãƒâ', 'åwe', 'šâ'])\n",
    "\n",
    "word_list = []\n",
    "# text_dict = {}\n",
    "for i in range(len(df)):\n",
    "    words = df['Text'][i].replace('\\n',\" \").lower().split()\n",
    "    u = [word for word in words if word not in stop_words]\n",
    "    # text_dict.update({' '.join(u):i})\n",
    "    clean_text = ' '.join(u).translate(translator)\n",
    "    df.loc[i, 'Text_clean'] = clean_text\n",
    "    word_list.append(clean_text.split())\n",
    "\n",
    "flat_list = []\n",
    "for sublist in word_list:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "\n",
    "counter = collections.Counter(flat_list)\n",
    "frequent_words = counter.most_common()\n",
    "\n",
    "unique_word_dict = {}\n",
    "for word in flat_list:\n",
    "    unique_word_dict.setdefault(\n",
    "        word, len(unique_word_dict)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_clean'] = df['Text']\n",
    "#punct = string.punctuation\n",
    "characters = string.punctuation + '–0123456789‘’“”ãƒâšå' \n",
    "translator = str.maketrans('', '', characters)\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"i'm\", \"i've\", \"i'll\", \"i'd\", \"  \", 'uh', \"ah\", \"aah\", 'weve', \"we've\", \"we'd\", \"we'll\",  \"we're\",\n",
    "'aah', 'aarp', 'aayuh'])\n",
    "\n",
    "word_list = []\n",
    "# text_dict = {}\n",
    "for i in range(len(df)):\n",
    "    text = df['Text'][i].lower().translate(translator)\n",
    "    u = [word for word in text.split() if word not in stop_words]\n",
    "    # text_dict.update({' '.join(u):i})\n",
    "    clean_text = ' '.join(u)\n",
    "    df.loc[i, 'Text_clean'] = clean_text\n",
    "    word_list.append(u)\n",
    "\n",
    "flat_list = []\n",
    "for sublist in word_list:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "\n",
    "counter = collections.Counter(flat_list)\n",
    "frequent_words = counter.most_common()\n",
    "\n",
    "unique_word_dict = {}\n",
    "for word in flat_list:\n",
    "    unique_word_dict.setdefault(\n",
    "        word, len(unique_word_dict)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abandon', 'abandoned', 'abandoning', ..., 'zippo', 'zone',\n",
       "       'zones'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Text_clean'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[\"date\"].dt.year < 2012\n",
    "\n",
    "x_train = X[mask]\n",
    "x_test = X[~mask]\n",
    "\n",
    "y_train = df.loc[mask, \"Verdict\"].values\n",
    "y_test = df.loc[~mask, \"Verdict\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base line model\n",
    "\n",
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, target_names= [\"NFS\", \"UFS\", \"CFS\"]))\n",
    "comparison_svm = classification_report(y_test, y_pred, target_names= [\"NFS\", \"UFS\", \"CFS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(min_samples_split=5)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred_rf = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_rf = classification_report(y_test, y_pred_rf, target_names= [\"NFS\", \"UFS\", \"CFS\"])\n",
    "print(comparison_rf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b82ba6ee2fa6fc8e732e2ad4d23a9f0e948eca091e73c38d7a866370a3b51fd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
