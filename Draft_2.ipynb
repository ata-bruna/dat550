{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect claims to fact check in political debates\n",
    "\n",
    "In this project you will implement various classifiers using both neural and feature based technqiues to detect which sentences in political debates should be fact checked.\n",
    "Dataset from ClaimBuster: https://zenodo.org/record/3609356 \n",
    "Evaluate your classifiers using the same metrics as http://ranger.uta.edu/~cli/pubs/2017/claimbuster-kdd17-hassan.pdf (Table 2)\n",
    "\n",
    "Classification report from sklearn provides everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Create advanced model(s) (suggestions are given below)\n",
    "#           -- Generate more features that a model can use. For example the context around the sentence, sentiment, named entities etc.\n",
    "#           -- Rule based classifier. For example, if sentence contains certain words, tags, statistics etc.\n",
    "#           -- Deep learning (word embeddings, transformer models etc.)\n",
    "#           -- Sub-sentence classifier. Long sentences may include several claims, so the goal is to mark the span of claim(s) within a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracemalloc import stop\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import collections\n",
    "import string\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import json\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>date</th>\n",
       "      <th>mos_before_election</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8211</td>\n",
       "      <td>Now, this is not standing still.</td>\n",
       "      <td>Richard M. Nixon</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.417840</td>\n",
       "      <td>-1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8515</td>\n",
       "      <td>So these are three programs which are quite mo...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>418</td>\n",
       "      <td>0.249581</td>\n",
       "      <td>-1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8514</td>\n",
       "      <td>The proposal advanced by you and by Mr. Javits...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>42</td>\n",
       "      <td>417</td>\n",
       "      <td>-0.626563</td>\n",
       "      <td>1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8513</td>\n",
       "      <td>It does not put a deficit on the Treasury.</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>416</td>\n",
       "      <td>-0.629486</td>\n",
       "      <td>1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8512</td>\n",
       "      <td>The third is medical care for the aged which i...</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Senator</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1960-09-26.txt</td>\n",
       "      <td>22</td>\n",
       "      <td>415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1960-09-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23528</th>\n",
       "      <td>34028</td>\n",
       "      <td>First of all, the media is so dishonest and so...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>17</td>\n",
       "      <td>907</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23529</th>\n",
       "      <td>34027</td>\n",
       "      <td>What I've seen -- what I've seen is so bad.</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>906</td>\n",
       "      <td>-0.669600</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23530</th>\n",
       "      <td>34026</td>\n",
       "      <td>I'll look at it at the time.</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>34039</td>\n",
       "      <td>So I talk about the corrupt media.</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Businessman</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23532</th>\n",
       "      <td>33341</td>\n",
       "      <td>They work hard, they do everything they can to...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Secretary of State</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>2016-10-19.txt</td>\n",
       "      <td>14</td>\n",
       "      <td>220</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23533 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence_id                                               Text  \\\n",
       "index                                                                   \n",
       "0             8211                   Now, this is not standing still.   \n",
       "1             8515  So these are three programs which are quite mo...   \n",
       "2             8514  The proposal advanced by you and by Mr. Javits...   \n",
       "3             8513         It does not put a deficit on the Treasury.   \n",
       "4             8512  The third is medical care for the aged which i...   \n",
       "...            ...                                                ...   \n",
       "23528        34028  First of all, the media is so dishonest and so...   \n",
       "23529        34027        What I've seen -- what I've seen is so bad.   \n",
       "23530        34026                       I'll look at it at the time.   \n",
       "23531        34039                 So I talk about the corrupt media.   \n",
       "23532        33341  They work hard, they do everything they can to...   \n",
       "\n",
       "                Speaker       Speaker_title Speaker_party         File_id  \\\n",
       "index                                                                       \n",
       "0      Richard M. Nixon      Vice President    REPUBLICAN  1960-09-26.txt   \n",
       "1       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "2       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "3       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "4       John F. Kennedy             Senator      DEMOCRAT  1960-09-26.txt   \n",
       "...                 ...                 ...           ...             ...   \n",
       "23528      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23529      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23530      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23531      Donald Trump         Businessman    REPUBLICAN  2016-10-19.txt   \n",
       "23532   Hillary Clinton  Secretary of State      DEMOCRAT  2016-10-19.txt   \n",
       "\n",
       "       Length  Line_number  Sentiment  Verdict       date  mos_before_election  \n",
       "index                                                                           \n",
       "0           6          114  -0.417840       -1 1960-09-26                    2  \n",
       "1           9          418   0.249581       -1 1960-09-26                    2  \n",
       "2          42          417  -0.626563        1 1960-09-26                    2  \n",
       "3           9          416  -0.629486        1 1960-09-26                    2  \n",
       "4          22          415   0.000000       -1 1960-09-26                    2  \n",
       "...       ...          ...        ...      ...        ...                  ...  \n",
       "23528      17          907   0.032300       -1 2016-10-19                    1  \n",
       "23529       9          906  -0.669600       -1 2016-10-19                    1  \n",
       "23530       7          905   0.000000       -1 2016-10-19                    1  \n",
       "23531       7          918   0.000000       -1 2016-10-19                    1  \n",
       "23532      14          220   0.361200       -1 2016-10-19                    1  \n",
       "\n",
       "[23533 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = pd.read_csv(\"data/crowdsourced.csv\", encoding='utf-8')\n",
    "file2 = pd.read_csv(\"data/groundtruth.csv\", encoding='utf-8')\n",
    "df = pd.concat([file1, file2])\n",
    "\n",
    "\n",
    "df[\"date\"] = df[\"File_id\"].str.strip(to_strip=\".txt\")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.sort_values(\"date\", inplace= True)\n",
    "df[\"mos_before_election\"] = 11 - df[\"date\"].dt.month\n",
    "\n",
    "df['index'] = pd.RangeIndex(len(df))\n",
    "df.set_index('index', inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    tokens = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    word_list = [word for word in text.split() if word not in stop_words]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_stemm(word_list):\n",
    "    \"\"\"Stemmers remove morphological affixes from words, leaving only the word stem.\"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    singles = [stemmer.stem(word) for word in word_list] \n",
    "    return singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(docs):\n",
    "\n",
    "    text_list = [] \n",
    "    for doc in docs:  \n",
    "        # 1. Remove punctuation and set as lower case\n",
    "        text = remove_punctuation(doc)\n",
    "\n",
    "        # 2. Remove stop words and extra spaces\n",
    "        word_list = remove_stop_words(text)\n",
    "        joined_text = \" \".join(word_list)\n",
    "        text_list.append(joined_text)\n",
    "        \n",
    "        # 3. Stemming\n",
    "        # word_stem = get_word_stemm(word_list)\n",
    "        # joined_text = \" \".join(word_stem)\n",
    "        # text_list.append(joined_text)\n",
    "\n",
    "\n",
    "    return text_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(df.Text.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.8, ngram_range=(1,3), stop_words='english')\n",
    "vectors = vectorizer.fit_transform(data)\n",
    "\n",
    "#dense = vectors.todense()\n",
    "#denselist = dense.tolist()\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aah', 'aarp', 'aarp said', ..., 'zones pass dang', 'zones said',\n",
       "       'zones said days'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aah' 'aarp' 'aarp said' ... 'zones pass dang' 'zones said'\n",
      " 'zones said days']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aah', 'aarp', 'aarp said', 'aarp said plan', 'aarp thinks',\n",
       "       'aarp thinks savings', 'aayuh', 'aayuh chairman',\n",
       "       'aayuh chairman joint', 'abandon', 'abandon nuclear',\n",
       "       'abandon nuclear ambitions', 'abandon peace',\n",
       "       'abandon peace process', 'abandon quest', 'abandon quest nuclear',\n",
       "       'abandon responsibilities', 'abandon trickle',\n",
       "       'abandon trickle economics', 'abandoned'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = []\n",
    "\n",
    "for description in denselist:\n",
    "    x=0\n",
    "    keywords = []\n",
    "    for word in description:\n",
    "        if word > 0:\n",
    "            keywords.append(feature_names[x])\n",
    "        x=x+1\n",
    "    all_keywords.append(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 25\n",
    "\n",
    "model = KMeans(n_clusters=true_k, init=\"k-means++\", max_iter=100, n_init=1)\n",
    "\n",
    "model.fit(vectors)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "with open (\"data/trc_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(true_k):\n",
    "        f.write(f\"Cluster {i}\")\n",
    "        f.write(\"\\n\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            f.write (' %s' % terms[ind],)\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_kmeans = model.fit_predict(vectors)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "scatter_plot_points = pca.fit_transform(vectors.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [  '#4E6888',\n",
    "            '#3515D5',\n",
    "            '#CF8ED0',\n",
    "            '#9075DC',\n",
    "            '#10E664',\n",
    "            '#0A717A',\n",
    "            '#00277C',\n",
    "            '#78862F',\n",
    "            '#4D641A',\n",
    "            '#E204BA',\n",
    "            '#30601F',\n",
    "            '#A14003',\n",
    "            '#910B50',\n",
    "            '#8F7175',\n",
    "            '#0D055D',\n",
    "            '#D2D5F9',\n",
    "            '#C2501F',\n",
    "            '#4B457E',\n",
    "            '#4BD0EF',\n",
    "            '#EA9A5B',\n",
    "            '#E7FA3E',\n",
    "            '#DE57EF',\n",
    "            '#5C2DF0',\n",
    "            '#2DBC02',\n",
    "            '#02C101' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Speaker_initials\"] = df[\"Speaker\"]\n",
    "df[\"party\"] = df[\"Speaker\"]\n",
    "for i in range(len(df[\"Speaker\"])):\n",
    "    initials = [s[0] for s in df[\"Speaker\"][i].split()]\n",
    "    party_abrev = [s[0] for s in df[\"Speaker_party\"][i].split()]\n",
    "\n",
    "    df.loc[i,\"Speaker_initials\"] = \"\".join(initials).upper()\n",
    "    df.loc[i,\"party\"] = \"\".join(party_abrev).upper()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [point[0] for point in scatter_plot_points]\n",
    "y_axis = [point[1] for point in scatter_plot_points]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (50, 50))\n",
    "\n",
    "ax.scatter(x_axis, y_axis, c= [colors[i] for i in indices_kmeans])\n",
    "\n",
    "# for i, name in enumerate(df.Speaker_initials):\n",
    "#     ax.annotate(name, (x_axis[i], y_axis[i]))\n",
    "\n",
    "plt.savefig('trc.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[\"date\"].dt.year < 2012\n",
    "\n",
    "\n",
    "x_train = df.loc[mask, \"Text_clean\"].values\n",
    "x_test = df.loc[~mask, \"Text_clean\"].values\n",
    "\n",
    "y_train = df.loc[mask, \"Verdict\"].values\n",
    "y_test = df.loc[~mask, \"Verdict\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 1000)\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base line model\n",
    "\n",
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, target_names= [\"NFS\", \"UFS\", \"CFS\"]))\n",
    "comparison_svm = classification_report(y_test, y_pred, target_names= [\"NFS\", \"UFS\", \"CFS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(min_samples_split=7)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred_rf = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_rf = classification_report(y_test, y_pred_rf, target_names= [\"NFS\", \"UFS\", \"CFS\"])\n",
    "print(comparison_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding using keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining vocabulary size\n",
    "vocabulary_size = list(unique_word_dict.values())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vocab = [one_hot(words, vocabulary_size) for words in df[\"Text_clean\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding max sentence length\n",
    "\n",
    "vec_lengths = []\n",
    "for i in encoded_vocab:\n",
    "    vec_lengths.append(len(i))\n",
    "\n",
    "\n",
    "max_length = np.unique(vec_lengths)[-1]\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs=pad_sequences(encoded_vocab,padding='pre',maxlen=max_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size,30,input_length=max_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b82ba6ee2fa6fc8e732e2ad4d23a9f0e948eca091e73c38d7a866370a3b51fd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
